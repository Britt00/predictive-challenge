{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, losses\n",
    "\n",
    "## For visualizing results\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to train get the generator functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterDataset(folder, classes=None, mode='train'):    \n",
    "    # initialize COCO api for instance annotations\n",
    "    annFile = '{}/annotations/instances_{}.json'.format(folder, mode)\n",
    "    coco = COCO(annFile)\n",
    "    \n",
    "    images = []\n",
    "    if classes!=None:\n",
    "        # iterate for each individual class in the list\n",
    "        for className in classes:\n",
    "            # get all images containing given categories\n",
    "            catIds = coco.getCatIds(catNms=className)\n",
    "            imgIds = coco.getImgIds(catIds=catIds)\n",
    "            images += coco.loadImgs(imgIds)\n",
    "    \n",
    "    else:\n",
    "        imgIds = coco.getImgIds()\n",
    "        images = coco.loadImgs(imgIds)\n",
    "    \n",
    "    # Now, filter out the repeated images\n",
    "    unique_images = []\n",
    "    for i in range(len(images)):\n",
    "        if images[i] not in unique_images:\n",
    "            unique_images.append(images[i])\n",
    "            \n",
    "    random.shuffle(unique_images)\n",
    "    dataset_size = len(unique_images)\n",
    "    \n",
    "    return unique_images, dataset_size, coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassName(classID, cats):\n",
    "    for i in range(len(cats)):\n",
    "        if cats[i]['id']==classID:\n",
    "            return cats[i]['name']\n",
    "    return None\n",
    "\n",
    "def getImage(imageObj, img_folder, input_image_size):\n",
    "    # Read and normalize an image\n",
    "    train_img = io.imread(img_folder + '/' + imageObj['file_name'])/255.0\n",
    "    # Resize\n",
    "    train_img = cv2.resize(train_img, input_image_size)\n",
    "    if (len(train_img.shape)==3 and train_img.shape[2]==3): # If it is a RGB 3 channel image\n",
    "        return train_img\n",
    "    else: # To handle a black and white image, increase dimensions to 3\n",
    "        stacked_img = np.stack((train_img,)*3, axis=-1)\n",
    "        return stacked_img\n",
    "    \n",
    "def getNormalMask(imageObj, classes, coco, catIds, input_image_size):\n",
    "    annIds = coco.getAnnIds(imageObj['id'], catIds=catIds, iscrowd=None)\n",
    "    anns = coco.loadAnns(annIds)\n",
    "    cats = coco.loadCats(catIds)\n",
    "    train_mask = np.zeros(input_image_size)\n",
    "    for a in range(len(anns)):\n",
    "        className = getClassName(anns[a]['category_id'], cats)\n",
    "        pixel_value = classes.index(className)+1\n",
    "        new_mask = cv2.resize(coco.annToMask(anns[a])*pixel_value, input_image_size)\n",
    "        train_mask = np.maximum(new_mask, train_mask)\n",
    "\n",
    "    # Add extra dimension for parity with train_img size [X * X * 3]\n",
    "    train_mask = train_mask.reshape(input_image_size[0], input_image_size[1], 1)\n",
    "    return train_mask  \n",
    "    \n",
    "def getBinaryMask(imageObj, coco, catIds, input_image_size):\n",
    "    annIds = coco.getAnnIds(imageObj['id'], catIds=catIds, iscrowd=None)\n",
    "    anns = coco.loadAnns(annIds)\n",
    "    train_mask = np.zeros(input_image_size)\n",
    "    for a in range(len(anns)):\n",
    "        new_mask = cv2.resize(coco.annToMask(anns[a]), input_image_size)\n",
    "        \n",
    "        #Threshold because resizing may cause extraneous values\n",
    "        new_mask[new_mask >= 0.5] = 1\n",
    "        new_mask[new_mask < 0.5] = 0\n",
    "\n",
    "        train_mask = np.maximum(new_mask, train_mask)\n",
    "\n",
    "    # Add extra dimension for parity with train_img size [X * X * 3]\n",
    "    train_mask = train_mask.reshape(input_image_size[0], input_image_size[1], 1)\n",
    "    return train_mask\n",
    "\n",
    "\n",
    "def dataGeneratorCoco(images, classes, coco, folder, \n",
    "                      input_image_size=(224,224), batch_size=4, mode='train', mask_type='binary'):\n",
    "    \n",
    "    img_folder = '{}/images/{}'.format(folder, mode)\n",
    "    dataset_size = len(images)\n",
    "    catIds = coco.getCatIds(catNms=classes)\n",
    "    \n",
    "    c = 0\n",
    "    while(True):\n",
    "        img = np.zeros((batch_size, input_image_size[0], input_image_size[1], 3)).astype('float')\n",
    "        mask = np.zeros((batch_size, input_image_size[0], input_image_size[1], 1)).astype('float')\n",
    "\n",
    "        for i in range(c, c+batch_size): #initially from 0 to batch_size, when c = 0\n",
    "            imageObj = images[i]\n",
    "            \n",
    "            ### Retrieve Image ###\n",
    "            train_img = getImage(imageObj, img_folder, input_image_size)\n",
    "            \n",
    "            ### Create Mask ###\n",
    "            if mask_type==\"binary\":\n",
    "                train_mask = getBinaryMask(imageObj, coco, catIds, input_image_size)\n",
    "            \n",
    "            elif mask_type==\"normal\":\n",
    "                train_mask = getNormalMask(imageObj, classes, coco, catIds, input_image_size)                \n",
    "            \n",
    "            # Add to respective batch sized arrays\n",
    "            img[i-c] = train_img\n",
    "            mask[i-c] = train_mask\n",
    "            \n",
    "        c+=batch_size\n",
    "        if(c + batch_size >= dataset_size):\n",
    "            c=0\n",
    "            random.shuffle(images)\n",
    "        yield img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeGenerator(gen):\n",
    "    img, mask = next(gen)\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    outerGrid = gridspec.GridSpec(1, 2, wspace=0.1, hspace=0.1)\n",
    "    \n",
    "    for i in range(2):\n",
    "        innerGrid = gridspec.GridSpecFromSubplotSpec(2, 2,\n",
    "                        subplot_spec=outerGrid[i], wspace=0.05, hspace=0.05)\n",
    "\n",
    "        for j in range(4):\n",
    "            ax = plt.Subplot(fig, innerGrid[j])\n",
    "            if(i==1):\n",
    "                ax.imshow(img[j])\n",
    "            else:\n",
    "                ax.imshow(mask[j][:,:,0])\n",
    "                \n",
    "            ax.axis('off')\n",
    "            fig.add_subplot(ax)        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentationsGenerator(gen, augGeneratorArgs, seed=None):\n",
    "    # Initialize the image data generator with args provided\n",
    "    image_gen = ImageDataGenerator(**augGeneratorArgs)\n",
    "    \n",
    "    # Remove the brightness argument for the mask. Spatial arguments similar to image.\n",
    "    augGeneratorArgs_mask = augGeneratorArgs.copy()\n",
    "    _ = augGeneratorArgs_mask.pop('brightness_range', None)\n",
    "    # Initialize the mask data generator with modified args\n",
    "    mask_gen = ImageDataGenerator(**augGeneratorArgs_mask)\n",
    "    \n",
    "    np.random.seed(seed if seed is not None else np.random.choice(range(9999)))\n",
    "    \n",
    "    for img, mask in gen:\n",
    "        seed = np.random.choice(range(9999))\n",
    "        # keep the seeds syncronized otherwise the augmentation of the images \n",
    "        # will end up different from the augmentation of the masks\n",
    "        g_x = image_gen.flow(255*img, \n",
    "                             batch_size = img.shape[0], \n",
    "                             seed = seed, \n",
    "                             shuffle=True)\n",
    "        g_y = mask_gen.flow(mask, \n",
    "                             batch_size = mask.shape[0], \n",
    "                             seed = seed, \n",
    "                             shuffle=True)\n",
    "        \n",
    "        img_aug = next(g_x)/255.0\n",
    "        \n",
    "        mask_aug = next(g_y)\n",
    "                   \n",
    "\n",
    "        yield img_aug, mask_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now, the actual training and generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filterDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29452/3807634378.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# -> Create filtered train dataset (using filterDataset())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mimages_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_size_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoco_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilterDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train2017'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# -> Create filtered val dataset (using filterDataset())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filterDataset' is not defined"
     ]
    }
   ],
   "source": [
    "folder = 'data/COCOdataset2017'\n",
    "classes = ['cat', 'dog', 'horse']\n",
    "batch_size = 4\n",
    "input_image_size = (224,224)\n",
    "mask_type = 'normal'\n",
    "augGeneratorArgs = dict(featurewise_center = False, \n",
    "                        samplewise_center = False,\n",
    "                        rotation_range = 5, \n",
    "                        width_shift_range = 0.01, \n",
    "                        height_shift_range = 0.01, \n",
    "                        brightness_range = (0.8,1.2),\n",
    "                        shear_range = 0.01,\n",
    "                        zoom_range = [1, 1.25],  \n",
    "                        horizontal_flip = True, \n",
    "                        vertical_flip = False,\n",
    "                        fill_mode = 'reflect',\n",
    "                        data_format = 'channels_last')\n",
    "\n",
    "# -> Create filtered train dataset (using filterDataset())\n",
    "images_t, dataset_size_t, coco_t = filterDataset(folder, classes,  mode='train2017')\n",
    "\n",
    "# -> Create filtered val dataset (using filterDataset()) \n",
    "images_v, dataset_size_v, coco_v = filterDataset(folder, classes,  mode='val2017')\n",
    "\n",
    "# -> Create train generator (using dataGeneratorCoco())\n",
    "train_gen = dataGeneratorCoco(images_t, classes, coco_t, folder,\n",
    "                            input_image_size, batch_size, mode, mask_type)\n",
    "train_gen_aug = augmentationsGenerator(train_gen, augGeneratorArgs)\n",
    "\n",
    "# -> Create val generator (using dataGeneratorCoco()) \n",
    "val_gen = dataGeneratorCoco(images_v, classes, coco_v, folder,\n",
    "                            input_image_size, batch_size, mode, mask_type)\n",
    "val_gen_aug = augmentationsGenerator(val_gen, augGeneratorArgs)\n",
    "\n",
    "# Set your parameters\n",
    "n_epochs = 4\n",
    "\n",
    "steps_per_epoch = dataset_size_train // batch_size\n",
    "validation_steps = dataset_size_val // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 111, 111, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 52, 52, 64)        36928     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,320\n",
      "Trainable params: 56,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = 'adam'\n",
    "lossFn = losses.SparseCategoricalCrossentropy(from_logits=True) \n",
    "\n",
    "# Compile your model first\n",
    "model.compile(loss = lossFn, optimizer = opt, metrics=['accuracy'])\n",
    "\n",
    "# Start the training process\n",
    "history = model.fit(x = train_gen_aug,\n",
    "                validation_data = val_gen_aug,\n",
    "                steps_per_epoch = steps_per_epoch,\n",
    "                validation_steps = validation_steps,\n",
    "                epochs = n_epochs,\n",
    "                verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tip:\n",
    "You can create a separate .py file (say cocoFunctions.py) and copy the code for the imports, filterDataset function, and dataGeneratorCoco + supporting functions. This will help make the code more systematic.\n",
    "\n",
    "You can then simply import the functions into any code by using:  \n",
    "from cocoFunctions import filterDataset, dataGeneratorCoco"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
